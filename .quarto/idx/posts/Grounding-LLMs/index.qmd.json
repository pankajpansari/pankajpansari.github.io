{"title":"Grounding Language Models in the Physical World","markdown":{"yaml":{"title":"Grounding Language Models in the Physical World","date":"2023-11-22","author":"Pankaj Pansari"},"containsRefs":false,"markdown":"\n\n<div style=\"text-align: justify\"> \n<style>\n.center {\n    display: block;\n    margin-left: auto;\n    margin-right: auto;\n}\n</style>\n\nI recently listened to a [podcast](https://www.therobotbrains.ai/copy-of-jitendra-malik) episode on The Robot Brains where Jitendra Malik, an eminent computer vision researcher, shared his thoughts and experiences on grounding large language models (LLMs) in the physical world and how to approach this through robotics. I summarize the discussion below:\n\n1. **Moravec's Paradox**\n\nMoravec wrote in 1988, \"it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility\" [^1].\n\nLLMs have shown enormous success recently on a wide variety of cognitive tasks. Among other benchmark tests, these systems have done well on challenging competitive exams. This gives us a feeling that these systems have acquired impressive intelligence. However, this holds true for tasks involving abstract, higher-level cognition. The challenging problems of locomotion and other desirable motor skills in robotics have not become solved as a result of this progress on LLMs. We seem to be still consistent with Moravec's Paradox.\n\n2. **Evolutionary Perspective** \n\nOn our human evolution journey, brain development followed the development of hands with opposable thumb; hand development in turn followed the development of bipedal walking which left our hands free. We developed sensorimotor skills first, language acquisition is a more recent phenomenon. If we think of human evolution on a 24-hour timeframe, langugage development corresponds only to the final 2-3 minutes. Clearly, all of intelligence cannot be said to reside in those final couple of minutes. Besides, different species of animals have different flavours of intelligence, and these are sophisticated in many cases. These animals do not possess language ability in the conventional sense. Hence, what we can learn from language alone may be inherently limited.\n\n3. **Human Learning and Development**\n\nWe can take inspiration from how babies and children learn. Babies interact with the world around them in a multi-modal way, using different senses. They gradually learn to manipulate objects and perform small experiments of their own. The acquisition of words at this stage is grounded in physical objects and interactions with them. So for instance when a mother says 'this is a ball', there is a visual input of the ball along with the motor desire to throw or catch a ball.\n\nWhen children go to school after the age of 5 and acquire knowledge through books, they already have a basic understanding of the world, people, and objects on which to build upon. This points to the need for a multi-modal and staged process of learning (*curriculum learning*).\n\n4. **Embodied AI**\n\nA new paradigm of intelligent models can be robots equipped with vision, touch, audio sensors with the ability to move, manipulate objects and interact with the real-world. As the robot learns more about the dynamics of the world, we can teach it basics of language. The rest of langugage acquisition will happen in an in-context manner, by combining atomic concepts, much like children do after age 5.\n\n5. **Rapid Adaptation of Motor Skills**\n\nThere is a compelling argument for this approach of acquiring atomic concepts that are grounded in the world followed by general language acquisition and development of abstract thinking. Any robotic system needs to be adaptable and robust. For instance, a robot must be able to walk on diverse, unseen terrains. The robot must be capable of learning new policies quickly, with the time-frame being task dependent. For example, a walking robot needs to learn to stabilize on a new terrain in about a second else the robot will fall. Just like humans need only a handful of examples to pick up a new concept, we can hope our ML systems modeled on lines of human learning and development, will be able to quickly adapt with a small number of simulations/trial and error.\n\n[^1]: Wikipedia contributors. \"Moravec's paradox.\" Wikipedia.\n\n\n","srcMarkdownNoYaml":"\n\n<div style=\"text-align: justify\"> \n<style>\n.center {\n    display: block;\n    margin-left: auto;\n    margin-right: auto;\n}\n</style>\n\nI recently listened to a [podcast](https://www.therobotbrains.ai/copy-of-jitendra-malik) episode on The Robot Brains where Jitendra Malik, an eminent computer vision researcher, shared his thoughts and experiences on grounding large language models (LLMs) in the physical world and how to approach this through robotics. I summarize the discussion below:\n\n1. **Moravec's Paradox**\n\nMoravec wrote in 1988, \"it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility\" [^1].\n\nLLMs have shown enormous success recently on a wide variety of cognitive tasks. Among other benchmark tests, these systems have done well on challenging competitive exams. This gives us a feeling that these systems have acquired impressive intelligence. However, this holds true for tasks involving abstract, higher-level cognition. The challenging problems of locomotion and other desirable motor skills in robotics have not become solved as a result of this progress on LLMs. We seem to be still consistent with Moravec's Paradox.\n\n2. **Evolutionary Perspective** \n\nOn our human evolution journey, brain development followed the development of hands with opposable thumb; hand development in turn followed the development of bipedal walking which left our hands free. We developed sensorimotor skills first, language acquisition is a more recent phenomenon. If we think of human evolution on a 24-hour timeframe, langugage development corresponds only to the final 2-3 minutes. Clearly, all of intelligence cannot be said to reside in those final couple of minutes. Besides, different species of animals have different flavours of intelligence, and these are sophisticated in many cases. These animals do not possess language ability in the conventional sense. Hence, what we can learn from language alone may be inherently limited.\n\n3. **Human Learning and Development**\n\nWe can take inspiration from how babies and children learn. Babies interact with the world around them in a multi-modal way, using different senses. They gradually learn to manipulate objects and perform small experiments of their own. The acquisition of words at this stage is grounded in physical objects and interactions with them. So for instance when a mother says 'this is a ball', there is a visual input of the ball along with the motor desire to throw or catch a ball.\n\nWhen children go to school after the age of 5 and acquire knowledge through books, they already have a basic understanding of the world, people, and objects on which to build upon. This points to the need for a multi-modal and staged process of learning (*curriculum learning*).\n\n4. **Embodied AI**\n\nA new paradigm of intelligent models can be robots equipped with vision, touch, audio sensors with the ability to move, manipulate objects and interact with the real-world. As the robot learns more about the dynamics of the world, we can teach it basics of language. The rest of langugage acquisition will happen in an in-context manner, by combining atomic concepts, much like children do after age 5.\n\n5. **Rapid Adaptation of Motor Skills**\n\nThere is a compelling argument for this approach of acquiring atomic concepts that are grounded in the world followed by general language acquisition and development of abstract thinking. Any robotic system needs to be adaptable and robust. For instance, a robot must be able to walk on diverse, unseen terrains. The robot must be capable of learning new policies quickly, with the time-frame being task dependent. For example, a walking robot needs to learn to stabilize on a new terrain in about a second else the robot will fall. Just like humans need only a handful of examples to pick up a new concept, we can hope our ML systems modeled on lines of human learning and development, will be able to quickly adapt with a small number of simulations/trial and error.\n\n[^1]: Wikipedia contributors. \"Moravec's paradox.\" Wikipedia.\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cosmo","title-block-banner":true,"title":"Grounding Language Models in the Physical World","date":"2023-11-22","author":"Pankaj Pansari"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}